# ================================
# CODE 1: Autonomous Research Assistant
# ================================
!pip install transformers torch PyMuPDF gensim

from transformers import pipeline
from gensim import corpora, models
import fitz  # PyMuPDF
import re

summarizer = pipeline("summarization")

# Extract text from PDF (e.g., downloaded arXiv paper)
def extract_text_from_pdf(file_path):
    doc = fitz.open(file_path)
    text = " ".join([page.get_text() for page in doc])
    return text

# Topic modeling from text using LDA
def extract_topics(text, num_topics=5):
    sentences = [re.findall(r"\b\w+\b", line.lower()) for line in text.split('.') if line]
    dictionary = corpora.Dictionary(sentences)
    corpus = [dictionary.doc2bow(text) for text in sentences]
    lda = models.LdaModel(corpus, num_topics=num_topics, id2word=dictionary, passes=10)
    return lda.print_topics()

# Autonomous Research Workflow
def analyze_research_paper(pdf_path):
    text = extract_text_from_pdf(pdf_path)
    summary = summarizer(text[:4000])  # summarizing first 4000 chars
    topics = extract_topics(text)
    return summary, topics

# Usage example:
# summary, topics = analyze_research_paper("your_arxiv_paper.pdf")
# print("Summary:", summary)
# print("Topics:", topics)


# ================================
# CODE 2: Multilingual Legal Contract Analyzer
# ================================
!pip install transformers spacy
!python -m spacy download en_core_web_sm

import spacy
from transformers import pipeline

ner = pipeline("ner", aggregation_strategy="simple")
summarizer = pipeline("summarization")
nlp = spacy.load("en_core_web_sm")

# Legal contract analyzer
def analyze_contract(text):
    obligations = []
    risks = []

    for sent in text.split('.'):
        if any(kw in sent.lower() for kw in ["shall", "must", "agree", "responsible"]):
            obligations.append(sent.strip())
        if any(kw in sent.lower() for kw in ["liability", "risk", "loss", "damages"]):
            risks.append(sent.strip())

    named_entities = ner(text)
    summary = summarizer(text[:1000])  # summarize part of text

    return {
        "Obligations": obligations,
        "Risks": risks,
        "Named Entities": named_entities,
        "Summary": summary
    }

# Usage example:
# result = analyze_contract(contract_text)
# print(result)


# ================================
# CODE 3: Persona-Aware Conversational Agent
# ================================
!pip install transformers

from transformers import pipeline, Conversation, ConversationalPipeline

conversation_pipeline = pipeline("conversational")
sentiment = pipeline("sentiment-analysis")

# Maintain persona and memory
user_profile = {
    "name": "Alex",
    "traits": ["curious", "analytical"],
    "emotion_history": []
}

conversation_memory = []

# Conversational agent

def persona_aware_chat(user_input):
    emotion = sentiment(user_input)[0]
    user_profile['emotion_history'].append(emotion)
    convo = Conversation(user_input)
    result = conversation_pipeline(convo)
    conversation_memory.append({"user": user_input, "bot": result.generated_responses[-1], "emotion": emotion})
    return result.generated_responses[-1]

# Usage:
# response = persona_aware_chat("I'm feeling a bit anxious today.")
# print(response)
# print(user_profile['emotion_history'])

